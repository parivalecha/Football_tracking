# -*- coding: utf-8 -*-
"""TRIAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qfufSC77-RCq2OuNL7gldCoSrk-3MFP9
"""

!pip install opencv-python opencv-python-headless

import cv2
import numpy as np
from google.colab import files
from google.colab.patches import cv2_imshow

# Function to process the video
def process_video(video_path):
    cap = cv2.VideoCapture(video_path)

    # Parameters for Lucas-Kanade optical flow
    lk_params = dict(winSize=(15, 15), maxLevel=2,
                     criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))

    # Create a background subtractor
    background_subtractor = cv2.createBackgroundSubtractorMOG2()

    # Define initial points for tracking (empty to start)
    prev_points = None
    prev_gray = None

    # Kalman Filter setup
    kalman = cv2.KalmanFilter(4, 2)
    kalman.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)
    kalman.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)
    kalman.processNoiseCov = np.array([[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 5, 0], [0, 0, 0, 5]], np.float32) * 0.03

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        # Convert to grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

        # Apply background subtraction to detect movement
        fg_mask = background_subtractor.apply(frame)
        fg_mask = cv2.medianBlur(fg_mask, 5)

        # Find contours
        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # Process each contour
        for contour in contours:
            if 100 < cv2.contourArea(contour) < 2000:  # Ball typically has smaller area than players
                x, y, w, h = cv2.boundingRect(contour)
                aspect_ratio = float(w)/h
                if 0.75 < aspect_ratio < 1.3:  # Check for circularity (ball is round)
                    # Get the centroid of the ball
                    cx = x + w // 2
                    cy = y + h // 2
                    measured = np.array([[np.float32(cx)], [np.float32(cy)]])
                    kalman.correct(measured)

                    # Predict the next position of the ball
                    predicted = kalman.predict()
                    pred_x, pred_y = int(predicted[0]), int(predicted[1])

                    # Draw the predicted position and the bounding box
                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
                    cv2.circle(frame, (pred_x, pred_y), 5, (0, 0, 255), -1)  # Red dot for prediction

                    # Ensure valid coordinates for cropping
                    zoom_size = 100  # Zoom window size
                    top_left_y = max(0, pred_y - zoom_size)
                    bottom_right_y = min(frame.shape[0], pred_y + zoom_size)
                    top_left_x = max(0, pred_x - zoom_size)
                    bottom_right_x = min(frame.shape[1], pred_x + zoom_size)

                    # Avoid empty crops
                    if bottom_right_y > top_left_y and bottom_right_x > top_left_x:
                        zoom_frame = frame[top_left_y:bottom_right_y, top_left_x:bottom_right_x]
                        zoom_frame = cv2.resize(zoom_frame, (frame.shape[1], frame.shape[0]))

                        cv2_imshow(zoom_frame)
                    break  # Assuming we are tracking only one ball
        else:
            # If no ball is detected, display the original frame
            cv2_imshow(frame)

    cap.release()
    cv2.destroyAllWindows()

# Upload video
uploaded = files.upload()

# Process the uploaded video
for filename in uploaded.keys():
    process_video(filename)